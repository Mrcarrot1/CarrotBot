<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.ML.PCA</name>
    </assembly>
    <members>
        <member name="T:Microsoft.ML.Runtime.PCA.RandomizedPcaTrainer">
            <summary>
            This trainer trains an approximate PCA using Randomized SVD algorithm
            Reference: https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf
            </summary>
            <remarks>
            This PCA can be made into Kernel PCA by using Random Fourier Features transform
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Runtime.PCA.RandomizedPcaTrainer.#ctor(Microsoft.ML.Runtime.IHostEnvironment,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of <see cref="T:Microsoft.ML.Runtime.PCA.RandomizedPcaTrainer"/>.
            </summary>
            <param name="env">The local instance of the <see cref="T:Microsoft.ML.Runtime.IHostEnvironment"/>.</param>
            <param name="featureColumn">The name of the feature column.</param>
            <param name="weightColumn">The name of the weight column.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="oversampling">Oversampling parameter for randomized PCA training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The seed for random number generation.</param>
        </member>
        <member name="M:Microsoft.ML.Runtime.PCA.RandomizedPcaTrainer.PostProcess(Microsoft.ML.Runtime.Data.VBuffer{System.Single}[],System.Single[],System.Single[],System.Int32,System.Int32)">
            <summary>
            Modifies <paramref name="y"/> in place so it becomes <paramref name="y"/> * eigenvectors / eigenvalues.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Runtime.PCA.PcaPredictor">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="M:Microsoft.ML.Runtime.PCA.PcaPredictor.GetEigenVectors(Microsoft.ML.Runtime.Data.VBuffer{System.Single}[]@,System.Int32@)">
            <summary>
            Copies the top eigenvectors of the covariance matrix of the training data
            into a set of buffers.
            </summary>
            <param name="vectors">A possibly reusable set of vectors, which will
            be expanded as necessary to accomodate the data.</param>
            <param name="rank">Set to the rank, which is also the logical length
            of <paramref name="vectors"/>.</param>
        </member>
        <member name="M:Microsoft.ML.Runtime.PCA.PcaPredictor.GetMean(Microsoft.ML.Runtime.Data.VBuffer{System.Single}@)">
            <summary>
            Copies the mean vector of the training data.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Runtime.Data.PcaTransform">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="M:Microsoft.ML.Runtime.Data.PcaTransform.#ctor(Microsoft.ML.Runtime.IHostEnvironment,Microsoft.ML.Runtime.Data.PcaTransform.Arguments,Microsoft.ML.Runtime.Data.IDataView)">
            <summary>
            Public constructor corresponding to SignatureDataTransform.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Runtime.Data.PcaEstimator">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="M:Microsoft.ML.Runtime.Data.PcaEstimator.#ctor(Microsoft.ML.Runtime.IHostEnvironment,System.String,System.String,System.Int32,System.Action{Microsoft.ML.Runtime.Data.PcaTransform.Arguments})">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
            <param name="env">The environment.</param>
            <param name="inputColumn">Input column to apply PCA on.</param>
            <param name="outputColumn">Output column. Null means <paramref name="inputColumn" /> is replaced.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="advancedSettings">A delegate to apply all the advanced arguments to the algorithm.</param>
        </member>
        <member name="M:Microsoft.ML.Runtime.Data.PcaEstimator.#ctor(Microsoft.ML.Runtime.IHostEnvironment,System.ValueTuple{System.String,System.String}[],System.Int32,System.Action{Microsoft.ML.Runtime.Data.PcaTransform.Arguments})">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
            <param name="env">The environment.</param>
            <param name="columns">Pairs of columns to run the PCA on.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="advancedSettings">A delegate to apply all the advanced arguments to the algorithm.</param>
        </member>
        <member name="T:Microsoft.ML.Runtime.Data.PcaEstimatorExtensions">
            <summary>
            Extensions for statically typed <see cref="T:Microsoft.ML.Runtime.Data.PcaEstimator"/>.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Runtime.Data.PcaEstimatorExtensions.ToPrincipalComponents(Microsoft.ML.StaticPipe.Vector{System.Single},System.Int32,System.Action{Microsoft.ML.Runtime.Data.PcaTransform.Arguments})">
            <summary>Replace current vector with its principal components. Can significantly reduce size of vector.</summary>
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
            <param name="input">The column to apply PCA to.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="advancedSettings">A delegate to apply all the advanced arguments to the algorithm.</param>
        </member>
    </members>
</doc>
